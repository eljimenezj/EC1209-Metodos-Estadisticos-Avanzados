---
title: "Actividad de evaluación - Métodos Estadísticos Avanzados"
author: 
- Álvaro Villa Vélez
- Edgar Leandro Jiménez Jaimes
- Jorge Luis Rentería Roa
- Luis Rodrigo Vesga Vesga
- Santiago Echeverri Calderón

date: "3/5/2020"
output: html_document
---

<style type="text/css">

h1.title {
  font-size: 38px;
  color: Black;
  text-align: center;
}
h4.author { /* Header 4 - and the author and data headers use this too  */
    font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: Black;
  text-align: center;
}
h4.date { /* Header 4 - and the author and data headers use this too  */
  font-size: 18px;
  font-family: "Times New Roman", Times, serif;
  color: DarkBlue;
  text-align: center;
}
</style>

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Profesor Juan David Ospina Arango  
Maestría en Ciencia de los Datos y Analítica  
Universidad Eafit  
Semestre 01-2020  


# 1 - Introducción

**Objetivo:** Caracterizar las relaciones entre algunos indicadores macroeconómicos y los **costos de ventas** de las empresas colombianas del sector de la **construcción**.

El código del trabajo se encuentra en: https://github.com/eljimenezj/EC1209-Metodos-Estadisticos-Avanzados/


```{r message=FALSE, warning=FALSE}
# Instalar paquetes necesarios
packages <- c("readxl", "tuple", "readxl", "ggplot2", "pander", "gridExtra","lme4")
#install.packages(packages,dependencies = T) 

# Importamos las librerías necesarias
library("readxl")
library("tuple")
library("readxl")
library("ggplot2")
library("pander")
library("gridExtra")
library("lme4")
library("lmerTest")
library("bayestestR")
library("MuMIn")

```


Para el presente trabajo se seleccionaron especificamente las clasificaciones *4111* y *4112*, "Construcción de edificios residenciales" y "Construcción de edificios no residenciales" respectivamente.

La información financiera se descargó de la Superintendencia de Sociedades para los años 2016, 2017 y 2018 en archivos de Excel independientes. Para cada año se consolidaron los archivos "NIIF Plenas" y "NIIF Pymes", y se filtró la información para seleccionar el periodo de correspondiente a cada año.
Las variables macroecómicas anuales se obtuvieron de Bloomberg y se adicionaron manualmente al conjunto de datos de información financiera.  Las variables que se incluyeron son:
* Tasa de cambio (tasa promedio anual)
* Cuenta Corriente (saldo a fin de año)
* Inflación (tasa promedio anual)
* Inflación sin alimentos (tasa promedio anual)
* Tasa de desempleo (tasa promedio anual)
* Balance Fiscal (saldo a fin de año)
* Precio del Acero en dólares (precio medio anual)
* Índice percepción Fedesarrollo (promedio anual)
* Crecimiento PIB (tasa fin de año)
* Tasa de intervención del Banco de la República (tasa media anual)
* DTF a 90 días (tasa media anual)

La variable objetivo será **Costo de venta**,  variable con una alta disperión como se puede observar en el siguiente boxplot:


```{r echo=FALSE}
#library("readxl")

path = "C:/Users/Santiago/Google Drive/Trabajo final Metodos Avanzados/Datasets/Costos_NIIF_construccion_consolidado.xlsx"

Costos <- read_excel(path , sheet = "Sectores 4111-4112", col_names = TRUE)

boxplot(Costos$Costo_de_ventas/1000,
main = "Costos de venta",
xlab = "Costos de venta (COP millones)",
col = "grey",
border = "blue",
horizontal = TRUE,
notch = FALSE
)
options(scipen=999)
grid()
#summary(Costos$Costo_de_ventas)

```

Se puede observar que los datos se encuentran en un rango entre 0 y  572798 millones.  Esto se debe a los diferentes tamaños de empresas que se encuentran en el conjunto de datos. Con el fin de evitar los problemas de alta dispersión por la escala, se tomó la decisión de representar los costos de venta en términos relativos con respecto a los ingresos ordinarios (**costo sobre ingresos** ó **CSI**).
Con esta estandarización se espera que los valores se encuentren en un rango entre 0 y 1, sin embargo, se observan valores por fuera de este rango generados por registros atípicos en los que los costos superan en gran proporción a las ventas:


```{r echo=FALSE, message=FALSE, warning=FALSE}
# Creación columna Costos sobre Ingresos
Costos$Csi <- Costos$Costo_de_ventas/Costos$`Ingresos de actividades ordinarias`

boxplot(Costos$Csi,
main = "Costos sobre Ingreso CSI",
xlab = "CSI",
col = "grey",
border = "blue",
horizontal = TRUE,
notch = FALSE
)
grid()
```

A continuación realizamos un preprocesamiento al conjunto de datos que se consolidó de manera inicial, con el eliminar datos faltantes, datos extremos, columnas que no se van a emplear en el análisis y finalmente trabajar con un conjunto de datos final que será utilizado durante la modelación.  
También se filtraron las empresas que no tuvieran información financiera para los 3 años de estudio.

```{r}

# Eliminamos registros NA
Dataset <- as.data.frame(na.omit(Costos))

# Filtramos el dataset para tener costos sobre ingresos en un rango
Dataset <- Dataset[Dataset$Csi >=0.3 & Dataset$Csi<=1,]

# Utilizamos los NIT que esten para todos los periodo
NIT     <- as.data.frame(triplicate(Dataset$Nit))
colnames(NIT) <- "Nit"
Dataset <-merge(x=Dataset,y=NIT,by="Nit")

# Eliminamos columnas que no serán empleadas en el estudio
Dataset <- subset( Dataset, select = -c(Sector,Periodo, `Ingresos de actividades ordinarias`,
                                        Costo_de_ventas, Fuente))

# Ordenamiento del dataset en año (Ascendet) y Nit(Descendente)
Dataset <- Dataset[order(Dataset$Año, decreasing = FALSE),] # Ordenar Año 
Dataset <- Dataset[order(Dataset$Nit, decreasing = TRUE),]  # Ordenar por nit 
```


Con el fin de trabajar con cifras razonables y evitar que el modelo sea desvirtuado por particularidades atípicas se definió hacer un filtrado dejando únicamente las observaciones con CSI entre 0.3 y 1. Valores inferiores a 0.3 corresponden a empresas cuyos costos son extremadamente bajos con respecto a sus ingresos, un comportamiento que no es habitual y deben corresponder a particularidades de la información financiera de la empresa. Por el contrario valores superiores a 1 corresponden a empresas con costos mayores que sus ventas, situación también atípica que implica.

```{r echo=FALSE}
boxplot(Dataset$Csi,
main = "0.3 <= CSI <= 1",
xlab = "CSI",
col = "grey",
border = "blue",
horizontal = TRUE,
notch = FALSE
)
grid()
```

# 2 - Análisis exploratorio de datos

A continuación se va realizar y presentar un análisis exploratorio de los datos con algunas gráficas y análisis de las mismas.En esta sección se buscarán patrones y asociaciones en los datos que nos ayuden más adelante durante la etapa de modelación.

En el gráfico a continuación se presenta una muestra del conjunto de datos en donde en el eje Y se tiene el costo sobre ingresos (Csi) y en el eje X los años de análisis. Cada bloque del gráfico representa el comportamiento de un NIT (o empresa). En este se graficó podemos observar que el CSI tiene un intercepto distinto para cada NIT y esta situación conlleva a probar la hipótesis de que el intercepto del Csi varía según los individuos. Esto es, ajustar un modelo donde el intercepto se consideran como efectos aleatorios.

*Nota: Para efectos de visualización se consideró una muestra de 120 registros, es decir 40 nits cada uno con información de 3 años.*
```{r fig.width = 10, echo=FALSE}
# Grafica de variacion de costos por años en puntos
muestra <- Dataset[1:60,]
ni<-3
G <- length(muestra$Nit)/ni
grupo <- factor(rep(x=1:G, each=ni))

ggplot(data = muestra, # Tome los primeros 60 registros -> aprox. 20 nits.
       aes(x = as.factor(Año) , y = Csi, color = grupo)) +  geom_point() + theme_bw() +  facet_wrap(~ Nit) +   theme(legend.position = "none") +
labs(title = "Costos (CSI) por Año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")
```

Continuando con el mismo gráfico, realizamos un modelo de regresión lineal simple para cada NIT del conjunto de muestra donde regresemos el Csi con el tiempo, a manera de exploración inicial, y posteriormente realizamos la gráfica de la recta que se ajusta a cada NIT. A continuación se presenta los resultados de la regresión para cada NIT, en este podemos observar mejor cómo los interceptos son diferentes y visualmente es claro como cada Csi por nit tiene un comportamiento diferente.

```{r fig.width = 10,message = FALSE, echo=FALSE}
ggplot(data = muestra, # Tome los primeros 60 registros -> aprox. 20 nits.
       aes(x =Año , y = Csi, color = grupo)) +  geom_point()  + theme_bw() + 
  geom_smooth(method = lm,
              se     = FALSE, 
              col    = "black",
              size   = .5, 
              alpha  = .8)+
  facet_wrap(~ Nit) +   theme(legend.position = "none")+
labs(title = "Regresión lineal simple Costos ~ Año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")
```

En la gráfica a continuación se evidencia el comportamiento de la variable Csi durante el avance de los años, en este análisis se logra evidenciar de manera gráfica la aleatoriedad que se presentan en los interceptos de cada uno de los individuos. Estos valores oscilan entre 0.3 y 1, con una media aproximada al 0.79. 

```{r echo=FALSE}
summary(Dataset$Csi)
```

```{r echo=FALSE}
set.seed(42)
#ni<-3
#G <- length(Dataset$Nit)/ni
#g2 <- factor(rep(x=1:G, each=ni))

ggplot(data  = Dataset , 
       aes(x = as.factor(Año),
           y = Csi))+
  geom_point(size = 1.2,
             alpha = .8,)+
             #position = "jitter")+# to add some random noise for plotting purposes
  labs(title = "Dispersión costos por Año") +
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")
```

Pese a la visual anterior, la interpretación integral de los datos resulta compleja pues la agrupación de los datos en el mismo periodo no permite estimar cuán concentrados están los datos. Por ello, se agrega ruido sobre el eje X con una semilla establecida para garantizar que la dispersión en ellos permita identificar la ubicación de la  mayoría de registros.

```{r echo = FALSE, message = FALSE}
set.seed(42)
ni<-3
G <- length(Dataset$Nit)/ni
g2 <- factor(rep(x=1:G, each=ni))

ggplot(data  = Dataset ,
       aes(x = Año,
           y = Csi))+
  geom_point(size = 1.2,
             alpha = .8,
             position = "jitter")+# to add some random noise for plotting purposes
  theme_minimal()+
  scale_color_gradientn(colours = rainbow(270))+
  labs(title = "Dispersión Costos por Año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")

```

Durante los años, la participación de los costos sobre los ingresos han tenido una tendencia creciente sobre el total de los datos. Año tras año, los registros empiezan a estar más agrupados en la parte superior con una menor diferencia intercuartil entre ellos. Tal como se evidencia en la figura (Figura con tendencia y Box plot)

```{r echo=FALSE}
# Grafico de boxplots de costos por año 
ggplot(Dataset, aes(x = as.factor(Año), y = Csi)) +
        geom_boxplot()+
  labs(title = "Gráfico Boxplot de los costos por año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")
  
```



```{r echo=FALSE, message = FALSE}
set.seed(42)
ni<-3
G <- length(Dataset$Nit)/ni
g2 <- factor(rep(x=1:G, each=ni))

a <- ggplot(data  = Dataset[1:120,] ,
       aes(x = Año,
           y = Csi))+
  geom_point(size = 1.2,
             alpha = .8,
             position = "jitter")+# to add some random noise for plotting purposes
  geom_smooth(method = lm,
              se     = FALSE, 
              col    = "black",
              size   = .5, 
              alpha  = .8)+ # to add regression line
  theme_minimal()+
  scale_color_gradientn(colours = rainbow(270))+
  labs(title = "Costos por Año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")

```


```{r echo=FALSE, message=FALSE}

set.seed(42)
ni<-3
G <- length(Dataset$Nit)/ni
g2 <- factor(rep(x=1:G, each=ni))

b<-ggplot(data  = Dataset[1:120,] ,
       aes(x = Año,
           y = Csi,
           col= as.numeric(g2)*2))+
  geom_point(size = 1.2,
             alpha = .8, show.legend = FALSE,
             position = "jitter")+# to add some random noise for plotting purposes
    geom_smooth(method = lm,
              se     = FALSE, 
              col    = "black",
              size   = .5, 
              alpha  = .8)+
  scale_color_gradientn(colours = rainbow(270))+
  labs(title = "Costos NIT individual  por Año")+
  xlab("Años") +
  ylab("Costos sobre Ingreso (CSI)")
```


```{r echo=FALSE, message=FALSE}
ni<-3
G <- nrow(Dataset[1:120,])/ni
g2 <- factor(rep(x=1:G, each=ni))

c<-ggplot(data      = Dataset[1:120,],
         aes(x     = Año,
             y     = Csi,
             col   = as.numeric(g2)*2,
             group = as.numeric(g2)*2))+ #to add the colours for different classes
    geom_point(size     = 1.2,
               alpha    = .8, show.legend = FALSE,
               position = "jitter")+ #to add some random noise for plotting purposes
    theme_minimal()+
    theme(legend.position = "none")+
    scale_color_gradientn(colours = rainbow(270))+
    geom_smooth(method = lm,
                se     = FALSE, 
                size   = .5, 
                alpha  = .8)+ # to add regression line
    labs(title = "Regresión Costos ~ Año desagregado por NIT")+
    xlab("Años") +
    ylab("Costos sobre Ingreso (CSI)")
```

A continuación se presenta una serie de graficas que muestran: Regresión de costos (CSI) por año, una regresión de costos por año con una desagregación visual (colores) por NIT  y una Regresión de costos particulares para cada individuo (Nit) con respecto al avance de los años. Para efectos de visualización se consideró una muestra de 120 registros, es decir 40 nits cada uno con información de 3 años.

```{r fig.width = 10, echo=FALSE , message=FALSE}

grid.arrange(a,b,c,    layout_matrix = rbind(c(1, 2),
                        c(3)))


```

Estos últimos 3 gráficos, ayudan a evidenciar que el intercepto debe ser aleatorio en la modelación, por lo cual consideramos que al realizar este análisis visual hay una tendencia creciente en el Csi por año pero sabemos que año NO es un variable explicativa de Csi y solo la incluimos para efectos visuales. Por lo cual las regresiones de las gráficas anteriores son solo ilustrativas.

Una vez analizado los Csi en función del tiempo (recordamos que año no es una variable), haremos un análisis similar al anterior pero ya contra variables macroeconómicas que si creemos pueden afectar nuestro modelo.  

**Observemos entonces el comportamiento de los costos de cada NIT por variables economicas:**
```{r echo=FALSE} 
# DTF90, TASA DE CAMBIO, CUENTA CORRIENTE, TASA INTERVENCION

# DTF
ni<-3
G <- nrow(Dataset[1:120,])/ni
g2 <- factor(rep(x=1:G, each=ni))

d <-ggplot(data      = Dataset[1:120,],
       aes(x     = DTF90,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por DTF90")+
  xlab("DTF por año") +
  ylab("Costos sobre Ingreso (CSI)")


# TASA CAMBIO
e<-ggplot(data      = Dataset[1:120,],
       aes(x     = Tasa_Cambio,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Tasa de cambio")+ 
  xlab("Tasa de cambio por año") +
  ylab("Costos sobre Ingreso (CSI)")


# CUENTA CORRIENTE
f<-ggplot(data      = Dataset[1:120,],
       aes(x     = Cuenta_Corriente,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Cuenta_Corriente")+ 
  xlab("Cuenta_Corriente por año") +
  ylab("Costos sobre Ingreso (CSI)")


# TASA INTERVENCION
g<-ggplot(data      = Dataset[1:120,],
       aes(x     = Tasa_intervencion,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Tasa_intervencion")+ 
  xlab("Tasa_intervencion por año") +
  ylab("Costos sobre Ingreso (CSI)")
```


```{r fig.width = 10, echo=FALSE,message=FALSE}

grid.arrange(d,e,f,g,  ncol=2)
```


```{r echo=FALSE} 
# INFLACION, INFLACION_SA, DESEMPLEO, BALANCE FISCAL

# INFLACION
ni<-3
G <- nrow(Dataset[1:120,])/ni
g2 <- factor(rep(x=1:G, each=ni))

h <-ggplot(data      = Dataset[1:120,],
       aes(x     = Inflacion,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Inflacion")+
  xlab("Inflacion por año") +
  ylab("Costos sobre Ingreso (CSI)")


# INFLACION SA
i <-ggplot(data      = Dataset[1:120,],
       aes(x     = Inflacion_SA,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Inflacion_SA")+
  xlab("Inflacion_SA por año") +
  ylab("Costos sobre Ingreso (CSI)")



# DESEMPLEO
j <-ggplot(data      = Dataset[1:120,],
       aes(x     = Desempleo,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Desempleo")+
  xlab("Desempleo por año") +
  ylab("Costos sobre Ingreso (CSI)")



# BALANCE FISCAL
k <-ggplot(data      = Dataset[1:120,],
       aes(x     = Balance_Fiscal,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Balance_Fiscal")+
  xlab("Balance_Fiscal por año") +
  ylab("Costos sobre Ingreso (CSI)")
```


```{r fig.width = 10, echo=FALSE,message=FALSE}

grid.arrange(h,i,j,k,  ncol=2)
```


```{r echo=FALSE} 
# ACERO, FEDESARROLLO, CRECIMIENTO PIB

# ACERO
ni<-3
G <- nrow(Dataset[1:120,])/ni
g2 <- factor(rep(x=1:G, each=ni))

l <-ggplot(data      = Dataset[1:120,],
       aes(x     = Acero,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Acero")+
  xlab("Acero por año") +
  ylab("Costos sobre Ingreso (CSI)")


m <-ggplot(data      = Dataset[1:120,],
       aes(x     = Fedesarrollo,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Fedesarrollo")+
  xlab("Fedesarrollo por año") +
  ylab("Costos sobre Ingreso (CSI)")

n <-ggplot(data      = Dataset[1:120,],
       aes(x     = Crecimiento_PIB,
           y     = Csi,
           col   = as.numeric(g2)*2,
           group = as.numeric(g2)*2))+ #to add the colours for different classes
  geom_point(size     = 1.2,
             alpha    = .8,
             position = "jitter")+ #to add some random noise for plotting purposes
  theme_minimal()+
  theme(legend.position = "none")+
  scale_color_gradientn(colours = rainbow(270))+
  geom_smooth(method = lm,
              se     = FALSE,
              size   = .5, 
              alpha  = .8)+ # to add regression line
  labs(title = "Costos por Crecimiento_PIB")+
  xlab("Crecimiento_PIB por año") +
  ylab("Costos sobre Ingreso (CSI)")
```

```{r fig.width = 10, echo=FALSE,message=FALSE}

grid.arrange(l,m,n,    layout_matrix = rbind(c(1, 2),
                        c(3)))
```


Al ver las gráficas del comportamiento de los costos de cada NIT por las variables macroeconomicas, se puede conlcuir de igual manera que el intercepto debe ser aleatorio (un NIT es cada color), pero visualmente poco logramos observar alguna relación entre el comportamiento del Csi y algunas de  las variables macro analizadas, por lo que utilizaremos un análisis más robusto estadísticamente para poder estudiar si existen esas relaciones económicas. Este análisis consiste en hacer un modelo lineal mixto con intercepto aleatorio; donde el efecto aleatorio será dado por cada NIT en el intercepto y las variables macros tendrán un efecto fijo.  



# 3 - Modelación

Las variables se estandarizaron de lasiguiente forma:

* Tasas de cambio: Le restamos $3.000 y dividimos por $10, con el fin de ver la sensibilidad del usdcop. Utilizamos la referencia de $3.000 ya que en los años de análisis es cuando se empezó a devaluar fuerte la moneda y muchos presupuestos colocaron ese valor de referencia.

* Cuenta Corriente: Le restamos 3.5% ya que el numero de referencia para el deficit de cuenta corriente fue 3.5% que es el valor estructural para la economía Colombiana.

* Inflación: Colocamos como referencia el 3% que es el valor objetivo de inflación dado por el Banco de la Republica (rango entre 2% y 4%).

* Inflación sin Alimentos: Colocamos como referencia el 3% que es el valor objetivo de inflación dado por el Banco de la Republica (rango entre 2% y 4%).

* Desempleo: Utilizamos como referencia la tasa NAIRU, El término NAIRU es un acrónimo derivado de la expresión inglesa Non-Accelerating Inflation Rate of Unemployment (Tasa de desempleo no aceleradora de la inflación) que algunos estudios en Colombia hablan que es cercana al 9%.

* Balance Fiscal: No se normaliza porque el objetivo del gobierno es tenerlo en niveles del 0%.

* Precio Acero: El precio del acero ha oscilado entre $300 y $600 dólares, le restamos $400 y lo dividimos por $10, con el fin de ver la sensibilidad del acero.

* Encuesta de Fedesarrollo: No la normalizamos por ser un indice, que en el tiempo de estudio del análisis siempre se encontró en territorio negativo.

* PIB (crecimiento): Utilizamos el 3% como referencia, que es un nivel cercano a la tasa de crecimiento de Colombia del periodo de análisis. 

* Tasa de intervención del Banco de la Republica: Le restamos 6% que es la tasa neutral (aproximadamente 3% de inflación + 3% de PIB), esta es la tasa que no tiene efectos ni expansionistas ni contraccionistas en el crecimiento económico.

* Tasa DTF90: Análisis similar a la tasa de intervención del Banco de la Republica.


```{r}
Dataset$Tasa_Cambio       <- (Dataset$Tasa_Cambio-3000)/ 10
Dataset$Cuenta_Corriente  <- (Dataset$Cuenta_Corriente+3.5)
Dataset$Inflacion         <- (Dataset$Inflacion-3)    
Dataset$Inflacion_SA      <- (Dataset$Inflacion_SA-3)
Dataset$Desempleo         <- (Dataset$Desempleo-9)
Dataset$Balance_Fiscal    <- (Dataset$Balance_Fiscal)
Dataset$Acero             <- (Dataset$Acero-400)/10
Dataset$Fedesarrollo      <- (Dataset$Fedesarrollo)
Dataset$Crecimiento_PIB   <- (Dataset$Crecimiento_PIB-3) 
Dataset$Tasa_intervencion <- (Dataset$Tasa_intervencion-6)
Dataset$DTF90             <-(Dataset$DTF90-6)
```

### Modelo 1: regresión con intercepto aleatorio

En este primer modelo simple se realizará una regresión exclusivamente con efecto aleatorio en el intercepto con los datos agrupados a nivel de NIT.  El propósito es determinar si el intercepto efectivamente tiene un efecto aleatorio:

```{r}
model1 <- lmer(Csi ~ 1 + ( 1 | Dataset$Nit), REML = FALSE, data = Dataset)
performance::icc(model1)
ranova(model1)
```

Al hacer el análisis ANOVA repetido (rANOVA) de este primer modelo se puede comprobar las significancia del efecto aleatorio del intercepto. El coeficiente de correlación interclase (ICC) puede interpretarse como la proporción de la varianza explicada por la estructura de agrupación en la población, en este caso el 44% de la varianza del intercepto es explicada por los NITs.  Con esto confirmamos que el modelo con intercepto aleatorio es pertinente.

A continuación con el propósito de determinar la significancia de cada variable, probamos modelos con cada variable macroeconómica con efecto fijo y el intercepto con efecto aleatorio. Cada uno de estos modelos se comparó con el modelo 1 (modelo base de intercepto aleatorio) mediante una análisis de varianza ANOVA.
En este ejercicio encontramos que ninguno de los modelos con las variables macroeconómicas es significativamente mejor que el modelo 1, es decir, ninguno superó la prueba con ANOVA.

Sin embargo, encontramos que si aumentamos el nivel de significancia a 0.2, las 3 mejores variables son:  inflación (sin alimentos) y tasa de intervención.
A continuación se presentan los modelos para cada una de estas 3 variables con efecto fijo y efecto aleatorio en el intercepto:


### Modelo 2: intercepto aleatorio y la variable **'inflación (sin alimentos)'** con efecto fijo
```{r}
model2 <- lmer(Csi ~ 1+ Dataset$Inflacion_SA + ( 1 | Dataset$Nit) , REML = FALSE, data = Dataset )
summary(model2)
anova(model1, model2)
```


### Modelo 3: intercepto aleatorio y la variable **'tasa de intervención'** con efecto fijo

```{r}
model3 <- lmer(Csi ~ 1+ Dataset$Tasa_intervencion + ( 1 | Dataset$Nit) , REML = FALSE, data = Dataset )
summary(model3)
anova(model1, model3)
```

Sin embargo sin incluimos ambas variable en un mismo modelo, se obtiene un modelo de menor significancia con respecto a los anteriores:

### Modelo 4: intercepto aleatorio y la variables **'inflación sin alimentos' y 'tasa de intervención'** con efecto fijo

```{r}
model4 <- lmer(Csi ~ 1+ Dataset$Inflacion_SA + Dataset$Tasa_intervencion  + ( 1 | Dataset$Nit) , REML = FALSE, data = Dataset )
anova(model2, model4)
```



### Pruebas de ajuste
Para medir la capacidad de ajuste de los modelos usaremos las métricas propuestas por Nakagawa and Schielzeth (2013) - *"A general and simple method for obtaining R2 from generalized linear mixed‐effects model"*, las cuales permiten tener una aproximación similar a un R2 de un modelo lineal tradicional.

La métrica R2 marginal (R2m) describe la proporción de varianza explicada solo por los factores fijos, y la métrica R2 condicional (R2c) describe la proporción de varianza explicada por los factores fijos y aleatorios.

Ajuste del modelo1 (base):

```{r message=FALSE, warning=FALSE}
MuMIn::r.squaredGLMM(model1)
```

Ajuste del modelo2 (inflación_sa con efecto fijo e intercepto con efecto aleatorio):
```{r message=FALSE}
MuMIn::r.squaredGLMM(model2)
```

Al revisar el R2 también se observa que las variables macroeconómicas no mejoran el ajuste del modelo.  En el modelo 2, incluyendo la inflación sin alimentos, la proporción de varianza explicada sólo por los factores fijos es mínima.  Mientras que la proporción de la varianza explicada por los factores aleatorios es del 44%.

### Regresión para cada individuo y el modelo 2(muestra de 20 individuos)

```{r fig.width = 10, echo=FALSE,message=FALSE}
pred_inter_pend_aleatorio = Dataset$pred_inter_pend_aleatorio <- predict(model2)
muestra <- Dataset[1:60,]
ni<-3
G <- length(muestra$Nit)/ni
grupo <- factor(rep(x=1:G, each=ni))
ggplot(data = muestra, aes(x = Inflacion_SA, y = pred_inter_pend_aleatorio, as.numeric(grupo))) +
    geom_line() +
    geom_point(aes(x = Inflacion_SA, y = Csi, color = as.numeric(grupo))) +
    geom_abline(intercept = 0.776930, slope = 0.006105, color = "black", linetype = "dashed", size = 0.5) +
    theme_bw() +
    facet_wrap(~ Nit) +
    scale_color_gradientn(colours = rainbow(270))+
    ylab("Csi - Costo sobre ingreso")+
    theme(legend.position = "none")
```
La figura anterior corresponde a un modelo de intercepto aleatorio y la variable inflación (sin alimentos) con efecto fijo, en el que se permite que los interceptos varíen según los individuos. Las líneas continuas corresponden a la recta de regresión ajustada a los datos. Los puntos representan las observaciones (CSI por año) medidas en cada unas de las empresas (NITs). La línea negra discontinua representa el valor medio global de la distribución de los efectos aleatorios.


# 4 - Conclusiones

* En el análisis gráfico de los datos se evidenció que existen interceptos aleatorios, elaborando un modelo con intercepto aleatorio se ratifica lo observado. El coeficiente de correlación interclase (ICC) puede interpretarse como la proporción de la varianza explicada por la estructura de agrupación en la población, en este caso el ICC es de 44%, es decir, el 44% de la varianza del intercepto es explicada por los NITs.
* Tras aplicar modelos lineales mixtos con un nivel de significancia del 95% no se logra identificar ninguna variable que logre explicar los datos (al menos en su conjunto de entrenamiento). Luego de disiminur los niveles de confianza a 80% se encontró que las variables 'tasa de intervención' e 'inflación sin alimentos' permiten inferir el comportamiento de los costos (CSI), esto tiene sentido económico pues son variables relacionadas con el sector de construcción.
* A pesar de no haber obtenido un buen ajuste en el modelo, podemos caracterizar algunas relaciones de los betas de los modelos mixtos por aparte:
  + Inflación sin alimentos: Por cada 100 puntos básicos que aumente la inflacion_sa con respecto a la inflación_sa objetivo (3%), los costos aumentarán su participación sobre los ingresos en 61 puntos básicos por efecto del coeficiente.
  + Por cada 100 puntos básicos que aumente la tasa de intervención con respecto a la tasa neutral (6%), los costos aumentarán su participación sobre los ingresos en 48 puntos básicos por efecto del coeficiente.
* Las variables anteriores presentan coherencia económica dado que si la inflación (sin alimentos) y la tasa de intervención suben es esperado que tenga un efecto de incremento sobre los costos de venta de las empresas de construcción.
  


# 5 - Estimación del esfuerzo

```{r echo=FALSE, message=FALSE}
my_tbl <- tibble::tribble(
  ~Actividad, ~Porcentaje,
   "Consolidación de información",  "25%",
   "Transformación de varibles y análisis descriptivo",  "40%",
   "Ajuste y validación de modelos",  "25%",
   "Redacción del reporte", "10%"
  )
require(rhandsontable)
rhandsontable(my_tbl, rowHeaders = NULL,
               digits = 3, useTypes = FALSE, search = FALSE,
               width = NULL, height = NULL)
```

  
# 6 - Referencias

* Superintendencia de sociedades. Portal de Información Empresarial. Enlace: http://pie.supersociedades.gov.co/Pages/default.aspx#/

* Barajas, F., & López, J. (Abril-2020). Modelos Mixtos con R. Enlace: https://fhernanb.github.io/libro_modelos_mixtos/

* LME4 Tutorial. Enlace: https://www.rensvandeschoot.com/tutorials/lme4/

* Ospina, JD. (Abril-2020). Notas de clase métodos estadisticos avanzados. Universidad EAFIT.

* Bloomberg. Información Macroeconómica y commodities. Enlace: https://www.bloomberg.com/
